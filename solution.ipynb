{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test change\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook. For example:\n",
    "\n",
    "```\n",
    "class SmoothOperator(Node):\n",
    "  def __init__(self):\n",
    "    super(SmoothOperator,self).__init__()\n",
    "    self.arity = 1\n",
    "    self.symb = \"SmoothOperator\"\n",
    "\n",
    "  def _get_args_repr(self, args):\n",
    "    return self._get_typical_repr(args,'before')\n",
    "\n",
    "  def get_output(self, X):\n",
    "    c_outs = self._get_child_outputs(X)\n",
    "    return np.smoothOperation(c_outs[0])\n",
    "\n",
    "  def get_output_pt(self, X):\n",
    "    c_outs = self._get_child_outputs_pt(X)\n",
    "    return torch.smoothOperation(c_outs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "import genepro\n",
    "importlib.reload(genepro)\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "# importlib.reload(genepro.evo)\n",
    "# importlib.reload(genepro.node_impl)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#workaround for error 15:\n",
    "#OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity): #specifies the max length of the memory buffer by making deque() object\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args): #pushes new transition(state,action,nextstate, reward) onto memory\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size): #returns sample batch of transitions in memory\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self): #returns current length of the memory\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other): #changes and returns the existing memory\n",
    "      self.memory += other.memory\n",
    "      return self \n",
    "\n",
    "    def __add__(self, other): #leaves existing memory but creates and returns new combined memory\n",
    "      self.memory = self.memory + other.memory \n",
    "      return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function_pt(multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False):\n",
    "  memory = ReplayMemory(10000)\n",
    "  rewards = []\n",
    "\n",
    "  for _ in range(num_episodes):\n",
    "    # get initial state of the environment\n",
    "    observation = env.reset() #resets to initial state (first seed is chosen randomly, then stays the same)\n",
    "    observation = observation[0] #returns metric(?) of first observation\n",
    "    observation = np.array([(observation[0]/90), (observation[1]/90), (observation[2]/5), (observation[3]/5), (observation[4]/3.1415927), (observation[5]/5), observation[6], observation[7]])\n",
    "\n",
    "    for _ in range(episode_duration):\n",
    "      if render:\n",
    "        frames.append(env.render())\n",
    "\n",
    "      input_sample = torch.from_numpy(observation.reshape((1,-1))).float() #creates a tensor from a numpy array (shared memory)\n",
    "      \n",
    "      action = torch.argmax(multitree.get_output_pt(input_sample))\n",
    "      observation, reward, terminated, truncated, info = env.step(action.item()) #updates environment with input action\n",
    "      observation = np.array([(observation[0]/90), (observation[1]/90), (observation[2]/5), (observation[3]/5), (observation[4]/3.1415927), (observation[5]/5), observation[6], observation[7]])\n",
    "      \n",
    "      rewards.append(reward)\n",
    "      output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "      if (terminated or truncated) and not ignore_done:\n",
    "        break\n",
    "\n",
    "  fitness = np.sum(rewards)\n",
    "  \n",
    "  return fitness, memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_const const?\n",
      "value 2.0300633907318115\n",
      "changed value -0.7376863956451416\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from genepro import node\n",
    "from genepro import node_impl\n",
    "import numpy as np\n",
    "test_module = nn.Module()\n",
    "test_node = node.Node()\n",
    "test_const = node_impl.Constant()\n",
    "print(\"test_const\",test_const)\n",
    "print(\"value\",test_const.get_value())\n",
    "test_value = np.random.uniform(-5,0)\n",
    "test_const.set_value(test_value)\n",
    "print(\"changed value\",test_const.get_value())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available: False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 0 Steps | CPU 11.6 | RAM 49.5:   0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\Sarah\\anaconda3\\envs\\EA_env\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "\n",
      "Episode 0 Steps | CPU 47.9 | RAM 49.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 0 Steps | CPU 47.9 | RAM 49.7:   2%|2         | 2/100 [00:00<00:05, 16.67it/s]\n",
      "Episode 0 Steps | CPU 58.3 | RAM 49.8:   2%|2         | 2/100 [00:00<00:05, 16.67it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:   2%|2         | 2/100 [00:00<00:05, 16.67it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:   4%|4         | 4/100 [00:00<00:05, 16.66it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:   4%|4         | 4/100 [00:00<00:05, 16.66it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 49.8:   4%|4         | 4/100 [00:00<00:05, 16.66it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 49.8:   6%|6         | 6/100 [00:00<00:05, 16.67it/s]\n",
      "Episode 0 Steps | CPU 54.2 | RAM 49.8:   6%|6         | 6/100 [00:00<00:05, 16.67it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:   6%|6         | 6/100 [00:00<00:05, 16.67it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:   8%|8         | 8/100 [00:00<00:05, 17.23it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:   8%|8         | 8/100 [00:00<00:05, 17.23it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 49.8:   8%|8         | 8/100 [00:00<00:05, 17.23it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 49.8:  10%|#         | 10/100 [00:00<00:05, 16.52it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  10%|#         | 10/100 [00:00<00:05, 16.52it/s]\n",
      "Episode 0 Steps | CPU 58.3 | RAM 49.7:  10%|#         | 10/100 [00:00<00:05, 16.52it/s]\n",
      "Episode 0 Steps | CPU 58.3 | RAM 49.7:  12%|#2        | 12/100 [00:00<00:05, 16.11it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  12%|#2        | 12/100 [00:00<00:05, 16.11it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  12%|#2        | 12/100 [00:00<00:05, 16.11it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  14%|#4        | 14/100 [00:00<00:05, 15.87it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  14%|#4        | 14/100 [00:00<00:05, 15.87it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  14%|#4        | 14/100 [00:00<00:05, 15.87it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.8:  16%|#6        | 16/100 [00:01<00:05, 15.19it/s]\n",
      "Episode 0 Steps | CPU 52.1 | RAM 49.8:  16%|#6        | 16/100 [00:01<00:05, 15.19it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 49.8:  16%|#6        | 16/100 [00:01<00:05, 15.19it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 49.8:  18%|#8        | 18/100 [00:01<00:05, 14.20it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 49.9:  18%|#8        | 18/100 [00:01<00:05, 14.20it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.9:  18%|#8        | 18/100 [00:01<00:05, 14.20it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.9:  20%|##        | 20/100 [00:01<00:05, 13.89it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 49.9:  20%|##        | 20/100 [00:01<00:05, 13.89it/s]\n",
      "Episode 0 Steps | CPU 55.0 | RAM 49.9:  20%|##        | 20/100 [00:01<00:05, 13.89it/s]\n",
      "Episode 0 Steps | CPU 55.0 | RAM 49.9:  22%|##2       | 22/100 [00:01<00:05, 13.74it/s]\n",
      "Episode 0 Steps | CPU 55.0 | RAM 49.9:  22%|##2       | 22/100 [00:01<00:05, 13.74it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 49.9:  22%|##2       | 22/100 [00:01<00:05, 13.74it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 49.9:  24%|##4       | 24/100 [00:01<00:05, 13.52it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 49.9:  24%|##4       | 24/100 [00:01<00:05, 13.52it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 50.0:  24%|##4       | 24/100 [00:01<00:05, 13.52it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 50.0:  26%|##6       | 26/100 [00:01<00:05, 12.65it/s]\n",
      "Episode 0 Steps | CPU 51.4 | RAM 50.0:  26%|##6       | 26/100 [00:01<00:05, 12.65it/s]\n",
      "Episode 0 Steps | CPU 54.2 | RAM 50.0:  26%|##6       | 26/100 [00:01<00:05, 12.65it/s]\n",
      "Episode 0 Steps | CPU 54.2 | RAM 50.0:  28%|##8       | 28/100 [00:01<00:05, 12.10it/s]\n",
      "Episode 0 Steps | CPU 54.8 | RAM 50.0:  28%|##8       | 28/100 [00:01<00:05, 12.10it/s]\n",
      "Episode 0 Steps | CPU 51.9 | RAM 50.0:  28%|##8       | 28/100 [00:02<00:05, 12.10it/s]\n",
      "Episode 0 Steps | CPU 51.9 | RAM 50.0:  30%|###       | 30/100 [00:02<00:06, 11.35it/s]\n",
      "Episode 0 Steps | CPU 49.3 | RAM 50.0:  30%|###       | 30/100 [00:02<00:06, 11.35it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.0:  30%|###       | 30/100 [00:02<00:06, 11.35it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.0:  32%|###2      | 32/100 [00:02<00:06, 11.07it/s]\n",
      "Episode 0 Steps | CPU 51.4 | RAM 50.0:  32%|###2      | 32/100 [00:02<00:06, 11.07it/s]\n",
      "Episode 0 Steps | CPU 54.8 | RAM 50.0:  32%|###2      | 32/100 [00:02<00:06, 11.07it/s]\n",
      "Episode 0 Steps | CPU 54.8 | RAM 50.0:  34%|###4      | 34/100 [00:02<00:06, 10.70it/s]\n",
      "Episode 0 Steps | CPU 54.2 | RAM 50.1:  34%|###4      | 34/100 [00:02<00:06, 10.70it/s]\n",
      "Episode 0 Steps | CPU 51.4 | RAM 50.0:  34%|###4      | 34/100 [00:02<00:06, 10.70it/s]\n",
      "Episode 0 Steps | CPU 51.4 | RAM 50.0:  36%|###6      | 36/100 [00:02<00:05, 10.80it/s]\n",
      "Episode 0 Steps | CPU 51.4 | RAM 50.1:  36%|###6      | 36/100 [00:02<00:05, 10.80it/s]\n",
      "Episode 0 Steps | CPU 52.9 | RAM 50.1:  36%|###6      | 36/100 [00:02<00:05, 10.80it/s]\n",
      "Episode 0 Steps | CPU 52.9 | RAM 50.1:  38%|###8      | 38/100 [00:02<00:05, 10.87it/s]\n",
      "Episode 0 Steps | CPU 48.4 | RAM 50.1:  38%|###8      | 38/100 [00:02<00:05, 10.87it/s]\n",
      "Episode 0 Steps | CPU 51.2 | RAM 50.1:  38%|###8      | 38/100 [00:03<00:05, 10.87it/s]\n",
      "Episode 0 Steps | CPU 51.2 | RAM 50.1:  40%|####      | 40/100 [00:03<00:05, 10.91it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.1:  40%|####      | 40/100 [00:03<00:05, 10.91it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 50.1:  40%|####      | 40/100 [00:03<00:05, 10.91it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 50.1:  42%|####2     | 42/100 [00:03<00:05, 10.77it/s]\n",
      "Episode 0 Steps | CPU 52.8 | RAM 50.1:  42%|####2     | 42/100 [00:03<00:05, 10.77it/s]\n",
      "Episode 0 Steps | CPU 51.2 | RAM 50.1:  42%|####2     | 42/100 [00:03<00:05, 10.77it/s]\n",
      "Episode 0 Steps | CPU 51.2 | RAM 50.1:  44%|####4     | 44/100 [00:03<00:05, 10.68it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  44%|####4     | 44/100 [00:03<00:05, 10.68it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  44%|####4     | 44/100 [00:03<00:05, 10.68it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  46%|####6     | 46/100 [00:03<00:05, 10.78it/s]\n",
      "Episode 0 Steps | CPU 55.6 | RAM 50.2:  46%|####6     | 46/100 [00:03<00:05, 10.78it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  46%|####6     | 46/100 [00:03<00:05, 10.78it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  48%|####8     | 48/100 [00:03<00:04, 10.85it/s]\n",
      "Episode 0 Steps | CPU 52.4 | RAM 50.1:  48%|####8     | 48/100 [00:03<00:04, 10.85it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 50.1:  48%|####8     | 48/100 [00:03<00:04, 10.85it/s]\n",
      "Episode 0 Steps | CPU 51.7 | RAM 50.1:  50%|#####     | 50/100 [00:04<00:04, 10.72it/s]\n",
      "Episode 0 Steps | CPU 51.2 | RAM 50.1:  50%|#####     | 50/100 [00:04<00:04, 10.72it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  50%|#####     | 50/100 [00:04<00:04, 10.72it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  52%|#####2    | 52/100 [00:04<00:04, 10.64it/s]\n",
      "Episode 0 Steps | CPU 50.7 | RAM 50.1:  52%|#####2    | 52/100 [00:04<00:04, 10.64it/s]\n",
      "Episode 0 Steps | CPU 52.1 | RAM 50.1:  52%|#####2    | 52/100 [00:04<00:04, 10.64it/s]\n",
      "Episode 0 Steps | CPU 52.1 | RAM 50.1:  54%|#####4    | 54/100 [00:04<00:04, 10.74it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  54%|#####4    | 54/100 [00:04<00:04, 10.74it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  54%|#####4    | 54/100 [00:04<00:04, 10.74it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  56%|#####6    | 56/100 [00:04<00:04, 10.47it/s]\n",
      "Episode 0 Steps | CPU 51.4 | RAM 50.1:  56%|#####6    | 56/100 [00:04<00:04, 10.47it/s]\n",
      "Episode 0 Steps | CPU 53.6 | RAM 50.2:  56%|#####6    | 56/100 [00:04<00:04, 10.47it/s]\n",
      "Episode 0 Steps | CPU 53.6 | RAM 50.2:  58%|#####8    | 58/100 [00:04<00:03, 10.63it/s]\n",
      "Episode 0 Steps | CPU 47.6 | RAM 50.2:  58%|#####8    | 58/100 [00:04<00:03, 10.63it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.1:  58%|#####8    | 58/100 [00:04<00:03, 10.63it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.1:  60%|######    | 60/100 [00:05<00:03, 10.56it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  60%|######    | 60/100 [00:05<00:03, 10.56it/s]\n",
      "Episode 0 Steps | CPU 50.0 | RAM 50.2:  60%|######    | 60/100 [00:05<00:03, 11.59it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 1 Steps | CPU 53.8 | RAM 50.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 1 Steps | CPU 56.2 | RAM 50.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 1 Steps | CPU 56.2 | RAM 50.2:   2%|2         | 2/100 [00:00<00:06, 15.25it/s]\n",
      "Episode 1 Steps | CPU 54.2 | RAM 50.2:   2%|2         | 2/100 [00:00<00:06, 15.25it/s]\n",
      "Episode 1 Steps | CPU 58.3 | RAM 50.2:   2%|2         | 2/100 [00:00<00:06, 15.25it/s]\n",
      "Episode 1 Steps | CPU 58.3 | RAM 50.2:   4%|4         | 4/100 [00:00<00:07, 13.42it/s]\n",
      "Episode 1 Steps | CPU 70.5 | RAM 50.2:   4%|4         | 4/100 [00:00<00:07, 13.42it/s]\n",
      "Episode 1 Steps | CPU 61.1 | RAM 50.3:   4%|4         | 4/100 [00:00<00:07, 13.42it/s]\n",
      "Episode 1 Steps | CPU 61.1 | RAM 50.3:   6%|6         | 6/100 [00:00<00:07, 12.20it/s]\n",
      "Episode 1 Steps | CPU 65.8 | RAM 50.4:   6%|6         | 6/100 [00:00<00:07, 12.20it/s]\n",
      "Episode 1 Steps | CPU 66.7 | RAM 50.4:   6%|6         | 6/100 [00:00<00:07, 12.20it/s]\n",
      "Episode 1 Steps | CPU 66.7 | RAM 50.4:   8%|8         | 8/100 [00:00<00:07, 12.26it/s]\n",
      "Episode 1 Steps | CPU 81.7 | RAM 50.4:   8%|8         | 8/100 [00:00<00:07, 12.26it/s]\n",
      "Episode 1 Steps | CPU 54.4 | RAM 50.5:   8%|8         | 8/100 [00:00<00:07, 12.26it/s]\n",
      "Episode 1 Steps | CPU 54.4 | RAM 50.5:  10%|#         | 10/100 [00:00<00:06, 12.98it/s]\n",
      "Episode 1 Steps | CPU 54.9 | RAM 50.4:  10%|#         | 10/100 [00:00<00:06, 12.98it/s]\n",
      "Episode 1 Steps | CPU 57.4 | RAM 50.5:  10%|#         | 10/100 [00:00<00:06, 12.98it/s]\n",
      "Episode 1 Steps | CPU 57.4 | RAM 50.5:  12%|#2        | 12/100 [00:00<00:06, 13.01it/s]\n",
      "Episode 1 Steps | CPU 70.0 | RAM 50.5:  12%|#2        | 12/100 [00:00<00:06, 13.01it/s]\n",
      "Episode 1 Steps | CPU 55.6 | RAM 50.5:  12%|#2        | 12/100 [00:01<00:06, 13.01it/s]\n",
      "Episode 1 Steps | CPU 55.6 | RAM 50.5:  14%|#4        | 14/100 [00:01<00:06, 12.59it/s]\n",
      "Episode 1 Steps | CPU 51.7 | RAM 50.5:  14%|#4        | 14/100 [00:01<00:06, 12.59it/s]\n",
      "Episode 1 Steps | CPU 55.6 | RAM 50.6:  14%|#4        | 14/100 [00:01<00:06, 12.59it/s]\n",
      "Episode 1 Steps | CPU 55.6 | RAM 50.6:  16%|#6        | 16/100 [00:01<00:06, 12.48it/s]\n",
      "Episode 1 Steps | CPU 54.2 | RAM 50.6:  16%|#6        | 16/100 [00:01<00:06, 12.48it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.6:  16%|#6        | 16/100 [00:01<00:06, 12.48it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.6:  18%|#8        | 18/100 [00:01<00:06, 12.70it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.6:  18%|#8        | 18/100 [00:01<00:06, 12.70it/s]\n",
      "Episode 1 Steps | CPU 53.3 | RAM 50.7:  18%|#8        | 18/100 [00:01<00:06, 12.70it/s]\n",
      "Episode 1 Steps | CPU 53.3 | RAM 50.7:  20%|##        | 20/100 [00:01<00:06, 12.86it/s]\n",
      "Episode 1 Steps | CPU 53.3 | RAM 50.7:  20%|##        | 20/100 [00:01<00:06, 12.86it/s]\n",
      "Episode 1 Steps | CPU 54.9 | RAM 50.7:  20%|##        | 20/100 [00:01<00:06, 12.86it/s]\n",
      "Episode 1 Steps | CPU 54.9 | RAM 50.7:  22%|##2       | 22/100 [00:01<00:06, 12.22it/s]\n",
      "Episode 1 Steps | CPU 52.5 | RAM 50.6:  22%|##2       | 22/100 [00:01<00:06, 12.22it/s]\n",
      "Episode 1 Steps | CPU 55.0 | RAM 50.7:  22%|##2       | 22/100 [00:01<00:06, 12.22it/s]\n",
      "Episode 1 Steps | CPU 55.0 | RAM 50.7:  24%|##4       | 24/100 [00:01<00:06, 12.51it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.7:  24%|##4       | 24/100 [00:01<00:06, 12.51it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.7:  24%|##4       | 24/100 [00:01<00:06, 12.51it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.7:  26%|##6       | 26/100 [00:02<00:06, 12.24it/s]\n",
      "Episode 1 Steps | CPU 55.0 | RAM 50.8:  26%|##6       | 26/100 [00:02<00:06, 12.24it/s]\n",
      "Episode 1 Steps | CPU 51.7 | RAM 50.8:  26%|##6       | 26/100 [00:02<00:06, 12.24it/s]\n",
      "Episode 1 Steps | CPU 51.7 | RAM 50.8:  28%|##8       | 28/100 [00:02<00:05, 12.28it/s]\n",
      "Episode 1 Steps | CPU 53.3 | RAM 50.8:  28%|##8       | 28/100 [00:02<00:05, 12.28it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.8:  28%|##8       | 28/100 [00:02<00:05, 12.28it/s]\n",
      "Episode 1 Steps | CPU 50.0 | RAM 50.8:  30%|###       | 30/100 [00:02<00:05, 11.87it/s]\n",
      "Episode 1 Steps | CPU 51.4 | RAM 50.8:  30%|###       | 30/100 [00:02<00:05, 11.87it/s]\n",
      "Episode 1 Steps | CPU 59.7 | RAM 50.7:  30%|###       | 30/100 [00:02<00:05, 11.87it/s]\n",
      "Episode 1 Steps | CPU 59.7 | RAM 50.7:  32%|###2      | 32/100 [00:02<00:06, 11.02it/s]\n",
      "Episode 1 Steps | CPU 60.7 | RAM 50.7:  32%|###2      | 32/100 [00:02<00:06, 11.02it/s]\n",
      "Episode 1 Steps | CPU 67.0 | RAM 50.9:  32%|###2      | 32/100 [00:02<00:06, 11.02it/s]\n",
      "Episode 1 Steps | CPU 67.0 | RAM 50.9:  33%|###3      | 33/100 [00:02<00:05, 11.44it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 2 Steps | CPU 66.7 | RAM 50.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 2 Steps | CPU 61.7 | RAM 50.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 2 Steps | CPU 61.7 | RAM 50.9:   2%|2         | 2/100 [00:00<00:08, 12.09it/s]\n",
      "Episode 2 Steps | CPU 70.8 | RAM 51.0:   2%|2         | 2/100 [00:00<00:08, 12.09it/s]\n",
      "Episode 2 Steps | CPU 80.8 | RAM 51.0:   2%|2         | 2/100 [00:00<00:08, 12.09it/s]\n",
      "Episode 2 Steps | CPU 80.8 | RAM 51.0:   4%|4         | 4/100 [00:00<00:08, 11.32it/s]\n",
      "Episode 2 Steps | CPU 68.1 | RAM 51.0:   4%|4         | 4/100 [00:00<00:08, 11.32it/s]\n",
      "Episode 2 Steps | CPU 56.7 | RAM 51.1:   4%|4         | 4/100 [00:00<00:08, 11.32it/s]\n",
      "Episode 2 Steps | CPU 56.7 | RAM 51.1:   6%|6         | 6/100 [00:00<00:08, 11.22it/s]\n",
      "Episode 2 Steps | CPU 51.4 | RAM 51.1:   6%|6         | 6/100 [00:00<00:08, 11.22it/s]\n",
      "Episode 2 Steps | CPU 53.3 | RAM 51.2:   6%|6         | 6/100 [00:00<00:08, 11.22it/s]\n",
      "Episode 2 Steps | CPU 53.3 | RAM 51.2:   8%|8         | 8/100 [00:00<00:07, 11.70it/s]\n",
      "Episode 2 Steps | CPU 57.4 | RAM 51.2:   8%|8         | 8/100 [00:00<00:07, 11.70it/s]\n",
      "Episode 2 Steps | CPU 61.9 | RAM 51.2:   8%|8         | 8/100 [00:00<00:07, 11.70it/s]\n",
      "Episode 2 Steps | CPU 61.9 | RAM 51.2:  10%|#         | 10/100 [00:00<00:08, 10.59it/s]\n",
      "Episode 2 Steps | CPU 72.9 | RAM 51.4:  10%|#         | 10/100 [00:00<00:08, 10.59it/s]\n",
      "Episode 2 Steps | CPU 72.9 | RAM 51.4:  10%|#         | 10/100 [00:01<00:09,  9.80it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 3 Steps | CPU 52.4 | RAM 51.4:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 3 Steps | CPU 51.7 | RAM 51.4:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 3 Steps | CPU 51.7 | RAM 51.4:   2%|2         | 2/100 [00:00<00:07, 12.50it/s]\n",
      "Episode 3 Steps | CPU 75.0 | RAM 51.5:   2%|2         | 2/100 [00:00<00:07, 12.50it/s]\n",
      "Episode 3 Steps | CPU 100.0 | RAM 51.4:   2%|2         | 2/100 [00:00<00:07, 12.50it/s]\n",
      "Episode 3 Steps | CPU 100.0 | RAM 51.4:   4%|4         | 4/100 [00:00<00:13,  7.18it/s]\n",
      "Episode 3 Steps | CPU 81.0 | RAM 51.4:   4%|4         | 4/100 [00:00<00:13,  7.18it/s] \n",
      "Episode 3 Steps | CPU 62.5 | RAM 51.5:   4%|4         | 4/100 [00:00<00:13,  7.18it/s]\n",
      "Episode 3 Steps | CPU 62.5 | RAM 51.5:   6%|6         | 6/100 [00:00<00:10,  9.27it/s]\n",
      "Episode 3 Steps | CPU 57.4 | RAM 51.5:   6%|6         | 6/100 [00:00<00:10,  9.27it/s]\n",
      "Episode 3 Steps | CPU 63.9 | RAM 51.6:   6%|6         | 6/100 [00:00<00:10,  9.27it/s]\n",
      "Episode 3 Steps | CPU 63.9 | RAM 51.6:   8%|8         | 8/100 [00:00<00:09,  9.89it/s]\n",
      "Episode 3 Steps | CPU 65.3 | RAM 51.7:   8%|8         | 8/100 [00:00<00:09,  9.89it/s]\n",
      "Episode 3 Steps | CPU 61.7 | RAM 51.6:   8%|8         | 8/100 [00:00<00:09,  9.89it/s]\n",
      "Episode 3 Steps | CPU 61.7 | RAM 51.6:  10%|#         | 10/100 [00:00<00:08, 10.88it/s]\n",
      "Episode 3 Steps | CPU 51.7 | RAM 51.6:  10%|#         | 10/100 [00:01<00:08, 10.88it/s]\n",
      "Episode 3 Steps | CPU 53.3 | RAM 51.6:  10%|#         | 10/100 [00:01<00:08, 10.88it/s]\n",
      "Episode 3 Steps | CPU 53.3 | RAM 51.6:  12%|#2        | 12/100 [00:01<00:07, 11.36it/s]\n",
      "Episode 3 Steps | CPU 50.0 | RAM 51.6:  12%|#2        | 12/100 [00:01<00:07, 11.36it/s]\n",
      "Episode 3 Steps | CPU 51.7 | RAM 51.6:  12%|#2        | 12/100 [00:01<00:07, 11.36it/s]\n",
      "Episode 3 Steps | CPU 51.7 | RAM 51.6:  14%|#4        | 14/100 [00:01<00:07, 11.91it/s]\n",
      "Episode 3 Steps | CPU 53.3 | RAM 51.7:  14%|#4        | 14/100 [00:01<00:07, 11.91it/s]\n",
      "Episode 3 Steps | CPU 50.0 | RAM 51.7:  14%|#4        | 14/100 [00:01<00:07, 11.91it/s]\n",
      "Episode 3 Steps | CPU 50.0 | RAM 51.7:  16%|#6        | 16/100 [00:01<00:06, 12.06it/s]\n",
      "Episode 3 Steps | CPU 50.0 | RAM 51.7:  16%|#6        | 16/100 [00:01<00:06, 12.06it/s]\n",
      "Episode 3 Steps | CPU 52.8 | RAM 51.6:  16%|#6        | 16/100 [00:01<00:06, 12.06it/s]\n",
      "Episode 3 Steps | CPU 52.8 | RAM 51.6:  18%|#8        | 18/100 [00:01<00:06, 11.92it/s]\n",
      "Episode 3 Steps | CPU 52.2 | RAM 51.7:  18%|#8        | 18/100 [00:01<00:06, 11.92it/s]\n",
      "Episode 3 Steps | CPU 58.8 | RAM 51.6:  18%|#8        | 18/100 [00:01<00:06, 11.92it/s]\n",
      "Episode 3 Steps | CPU 58.8 | RAM 51.6:  20%|##        | 20/100 [00:01<00:06, 12.06it/s]\n",
      "Episode 3 Steps | CPU 53.6 | RAM 51.7:  20%|##        | 20/100 [00:01<00:06, 12.06it/s]\n",
      "Episode 3 Steps | CPU 49.2 | RAM 51.7:  20%|##        | 20/100 [00:01<00:06, 12.06it/s]\n",
      "Episode 3 Steps | CPU 49.2 | RAM 51.7:  22%|##2       | 22/100 [00:01<00:06, 12.16it/s]\n",
      "Episode 3 Steps | CPU 53.4 | RAM 51.6:  22%|##2       | 22/100 [00:01<00:06, 12.16it/s]\n",
      "Episode 3 Steps | CPU 54.1 | RAM 51.7:  22%|##2       | 22/100 [00:02<00:06, 12.16it/s]\n",
      "Episode 3 Steps | CPU 54.1 | RAM 51.7:  23%|##3       | 23/100 [00:02<00:07, 10.47it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 4 Steps | CPU 50.9 | RAM 51.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 4 Steps | CPU 55.7 | RAM 51.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 4 Steps | CPU 55.7 | RAM 51.7:   2%|2         | 2/100 [00:00<00:07, 13.18it/s]\n",
      "Episode 4 Steps | CPU 51.7 | RAM 51.7:   2%|2         | 2/100 [00:00<00:07, 13.18it/s]\n",
      "Episode 4 Steps | CPU 53.3 | RAM 51.7:   2%|2         | 2/100 [00:00<00:07, 13.18it/s]\n",
      "Episode 4 Steps | CPU 53.3 | RAM 51.7:   4%|4         | 4/100 [00:00<00:07, 13.21it/s]\n",
      "Episode 4 Steps | CPU 52.1 | RAM 51.7:   4%|4         | 4/100 [00:00<00:07, 13.21it/s]\n",
      "Episode 4 Steps | CPU 53.3 | RAM 51.8:   4%|4         | 4/100 [00:00<00:07, 13.21it/s]\n",
      "Episode 4 Steps | CPU 53.3 | RAM 51.8:   6%|6         | 6/100 [00:00<00:06, 13.61it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:   6%|6         | 6/100 [00:00<00:06, 13.61it/s]\n",
      "Episode 4 Steps | CPU 61.9 | RAM 51.8:   6%|6         | 6/100 [00:00<00:06, 13.61it/s]\n",
      "Episode 4 Steps | CPU 61.9 | RAM 51.8:   8%|8         | 8/100 [00:00<00:07, 12.45it/s]\n",
      "Episode 4 Steps | CPU 53.3 | RAM 51.8:   8%|8         | 8/100 [00:00<00:07, 12.45it/s]\n",
      "Episode 4 Steps | CPU 54.4 | RAM 51.7:   8%|8         | 8/100 [00:00<00:07, 12.45it/s]\n",
      "Episode 4 Steps | CPU 54.4 | RAM 51.7:  10%|#         | 10/100 [00:00<00:07, 12.44it/s]\n",
      "Episode 4 Steps | CPU 47.6 | RAM 51.8:  10%|#         | 10/100 [00:00<00:07, 12.44it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  10%|#         | 10/100 [00:00<00:07, 12.44it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  12%|#2        | 12/100 [00:00<00:06, 12.69it/s]\n",
      "Episode 4 Steps | CPU 58.3 | RAM 51.8:  12%|#2        | 12/100 [00:00<00:06, 12.69it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  12%|#2        | 12/100 [00:01<00:06, 12.69it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  14%|#4        | 14/100 [00:01<00:06, 12.86it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  14%|#4        | 14/100 [00:01<00:06, 12.86it/s]\n",
      "Episode 4 Steps | CPU 54.2 | RAM 51.8:  14%|#4        | 14/100 [00:01<00:06, 12.86it/s]\n",
      "Episode 4 Steps | CPU 54.2 | RAM 51.8:  16%|#6        | 16/100 [00:01<00:06, 12.71it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  16%|#6        | 16/100 [00:01<00:06, 12.71it/s]\n",
      "Episode 4 Steps | CPU 51.4 | RAM 51.8:  16%|#6        | 16/100 [00:01<00:06, 12.71it/s]\n",
      "Episode 4 Steps | CPU 51.4 | RAM 51.8:  18%|#8        | 18/100 [00:01<00:06, 12.13it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  18%|#8        | 18/100 [00:01<00:06, 12.13it/s]\n",
      "Episode 4 Steps | CPU 50.0 | RAM 51.8:  18%|#8        | 18/100 [00:01<00:06, 11.74it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 5 Steps | CPU 51.4 | RAM 51.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 5 Steps | CPU 50.0 | RAM 51.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 5 Steps | CPU 50.0 | RAM 51.9:   2%|2         | 2/100 [00:00<00:07, 13.04it/s]\n",
      "Episode 5 Steps | CPU 50.0 | RAM 51.8:   2%|2         | 2/100 [00:00<00:07, 13.04it/s]\n",
      "Episode 5 Steps | CPU 56.7 | RAM 52.0:   2%|2         | 2/100 [00:00<00:07, 13.04it/s]\n",
      "Episode 5 Steps | CPU 56.7 | RAM 52.0:   4%|4         | 4/100 [00:00<00:07, 13.15it/s]\n",
      "Episode 5 Steps | CPU 55.0 | RAM 51.9:   4%|4         | 4/100 [00:00<00:07, 13.15it/s]\n",
      "Episode 5 Steps | CPU 58.3 | RAM 52.0:   4%|4         | 4/100 [00:00<00:07, 13.15it/s]\n",
      "Episode 5 Steps | CPU 58.3 | RAM 52.0:   6%|6         | 6/100 [00:00<00:06, 13.70it/s]\n",
      "Episode 5 Steps | CPU 51.7 | RAM 52.0:   6%|6         | 6/100 [00:00<00:06, 13.70it/s]\n",
      "Episode 5 Steps | CPU 65.3 | RAM 52.0:   6%|6         | 6/100 [00:00<00:06, 13.70it/s]\n",
      "Episode 5 Steps | CPU 65.3 | RAM 52.0:   8%|8         | 8/100 [00:00<00:07, 11.97it/s]\n",
      "Episode 5 Steps | CPU 78.8 | RAM 52.1:   8%|8         | 8/100 [00:00<00:07, 11.97it/s]\n",
      "Episode 5 Steps | CPU 65.8 | RAM 52.1:   8%|8         | 8/100 [00:00<00:07, 11.97it/s]\n",
      "Episode 5 Steps | CPU 65.8 | RAM 52.1:  10%|#         | 10/100 [00:00<00:07, 11.33it/s]\n",
      "Episode 5 Steps | CPU 59.7 | RAM 52.1:  10%|#         | 10/100 [00:00<00:07, 11.33it/s]\n",
      "Episode 5 Steps | CPU 69.4 | RAM 52.2:  10%|#         | 10/100 [00:00<00:07, 11.33it/s]\n",
      "Episode 5 Steps | CPU 69.4 | RAM 52.2:  12%|#2        | 12/100 [00:01<00:08,  9.90it/s]\n",
      "Episode 5 Steps | CPU 96.4 | RAM 52.2:  12%|#2        | 12/100 [00:01<00:08,  9.90it/s]\n",
      "Episode 5 Steps | CPU 100.0 | RAM 52.2:  12%|#2        | 12/100 [00:01<00:08,  9.90it/s]\n",
      "Episode 5 Steps | CPU 100.0 | RAM 52.2:  13%|#3        | 13/100 [00:01<00:09,  9.24it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 6 Steps | CPU 100.0 | RAM 52.3:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 6 Steps | CPU 100.0 | RAM 52.3:   1%|1         | 1/100 [00:00<00:10,  9.16it/s]\n",
      "Episode 6 Steps | CPU 88.1 | RAM 52.4:   1%|1         | 1/100 [00:00<00:10,  9.16it/s] \n",
      "Episode 6 Steps | CPU 88.5 | RAM 52.3:   1%|1         | 1/100 [00:00<00:10,  9.16it/s]\n",
      "Episode 6 Steps | CPU 88.5 | RAM 52.3:   3%|3         | 3/100 [00:00<00:09, 10.16it/s]\n",
      "Episode 6 Steps | CPU 79.5 | RAM 52.3:   3%|3         | 3/100 [00:00<00:09, 10.16it/s]\n",
      "Episode 6 Steps | CPU 78.7 | RAM 52.3:   3%|3         | 3/100 [00:00<00:09, 10.16it/s]\n",
      "Episode 6 Steps | CPU 78.7 | RAM 52.3:   5%|5         | 5/100 [00:00<00:08, 11.06it/s]\n",
      "Episode 6 Steps | CPU 75.0 | RAM 52.3:   5%|5         | 5/100 [00:00<00:08, 11.06it/s]\n",
      "Episode 6 Steps | CPU 69.9 | RAM 52.4:   5%|5         | 5/100 [00:00<00:08, 11.06it/s]\n",
      "Episode 6 Steps | CPU 69.9 | RAM 52.4:   7%|7         | 7/100 [00:00<00:08, 11.31it/s]\n",
      "Episode 6 Steps | CPU 61.7 | RAM 52.3:   7%|7         | 7/100 [00:00<00:08, 11.31it/s]\n",
      "Episode 6 Steps | CPU 71.8 | RAM 52.3:   7%|7         | 7/100 [00:00<00:08, 11.31it/s]\n",
      "Episode 6 Steps | CPU 71.8 | RAM 52.3:   9%|9         | 9/100 [00:00<00:08, 11.02it/s]\n",
      "Episode 6 Steps | CPU 59.0 | RAM 52.3:   9%|9         | 9/100 [00:00<00:08, 11.02it/s]\n",
      "Episode 6 Steps | CPU 58.3 | RAM 52.3:   9%|9         | 9/100 [00:00<00:08, 11.02it/s]\n",
      "Episode 6 Steps | CPU 58.3 | RAM 52.3:  10%|#         | 10/100 [00:01<00:11,  8.00it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 7 Steps | CPU 89.8 | RAM 52.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 7 Steps | CPU 58.3 | RAM 52.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 7 Steps | CPU 58.3 | RAM 52.5:   2%|2         | 2/100 [00:00<00:07, 13.24it/s]\n",
      "Episode 7 Steps | CPU 50.0 | RAM 52.5:   2%|2         | 2/100 [00:00<00:07, 13.24it/s]\n",
      "Episode 7 Steps | CPU 57.4 | RAM 52.5:   2%|2         | 2/100 [00:00<00:07, 13.24it/s]\n",
      "Episode 7 Steps | CPU 57.4 | RAM 52.5:   4%|4         | 4/100 [00:00<00:07, 12.73it/s]\n",
      "Episode 7 Steps | CPU 60.9 | RAM 52.6:   4%|4         | 4/100 [00:00<00:07, 12.73it/s]\n",
      "Episode 7 Steps | CPU 56.9 | RAM 52.6:   4%|4         | 4/100 [00:00<00:07, 12.73it/s]\n",
      "Episode 7 Steps | CPU 56.9 | RAM 52.6:   6%|6         | 6/100 [00:00<00:07, 12.65it/s]\n",
      "Episode 7 Steps | CPU 58.9 | RAM 52.6:   6%|6         | 6/100 [00:00<00:07, 12.65it/s]\n",
      "Episode 7 Steps | CPU 50.0 | RAM 52.6:   6%|6         | 6/100 [00:00<00:07, 12.65it/s]\n",
      "Episode 7 Steps | CPU 50.0 | RAM 52.6:   8%|8         | 8/100 [00:00<00:07, 12.80it/s]\n",
      "Episode 7 Steps | CPU 52.9 | RAM 52.6:   8%|8         | 8/100 [00:00<00:07, 12.80it/s]\n",
      "Episode 7 Steps | CPU 50.0 | RAM 52.6:   8%|8         | 8/100 [00:00<00:07, 12.80it/s]\n",
      "Episode 7 Steps | CPU 50.0 | RAM 52.6:   9%|9         | 9/100 [00:00<00:07, 11.59it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 8 Steps | CPU 51.4 | RAM 52.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.6:   2%|2         | 2/100 [00:00<00:06, 15.01it/s]\n",
      "Episode 8 Steps | CPU 54.2 | RAM 52.6:   2%|2         | 2/100 [00:00<00:06, 15.01it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.7:   2%|2         | 2/100 [00:00<00:06, 15.01it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.7:   4%|4         | 4/100 [00:00<00:06, 14.47it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.7:   4%|4         | 4/100 [00:00<00:06, 14.47it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.7:   4%|4         | 4/100 [00:00<00:06, 14.47it/s]\n",
      "Episode 8 Steps | CPU 50.0 | RAM 52.7:   6%|6         | 6/100 [00:00<00:07, 13.13it/s]\n",
      "Episode 8 Steps | CPU 52.1 | RAM 52.8:   6%|6         | 6/100 [00:00<00:07, 13.13it/s]\n",
      "Episode 8 Steps | CPU 56.7 | RAM 52.8:   6%|6         | 6/100 [00:00<00:07, 13.13it/s]\n",
      "Episode 8 Steps | CPU 56.7 | RAM 52.8:   8%|8         | 8/100 [00:00<00:07, 12.67it/s]\n",
      "Episode 8 Steps | CPU 55.6 | RAM 52.8:   8%|8         | 8/100 [00:00<00:07, 12.67it/s]\n",
      "Episode 8 Steps | CPU 61.7 | RAM 52.8:   8%|8         | 8/100 [00:00<00:07, 12.67it/s]\n",
      "Episode 8 Steps | CPU 61.7 | RAM 52.8:   9%|9         | 9/100 [00:00<00:07, 11.41it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 9 Steps | CPU 51.4 | RAM 52.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 9 Steps | CPU 54.2 | RAM 52.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 9 Steps | CPU 54.2 | RAM 52.8:   2%|2         | 2/100 [00:00<00:06, 16.08it/s]\n",
      "Episode 9 Steps | CPU 50.0 | RAM 52.8:   2%|2         | 2/100 [00:00<00:06, 16.08it/s]\n",
      "Episode 9 Steps | CPU 51.7 | RAM 52.9:   2%|2         | 2/100 [00:00<00:06, 16.08it/s]\n",
      "Episode 9 Steps | CPU 51.7 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 13.53it/s]\n",
      "Episode 9 Steps | CPU 61.1 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 13.53it/s]\n",
      "Episode 9 Steps | CPU 50.0 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 13.53it/s]\n",
      "Episode 9 Steps | CPU 50.0 | RAM 52.9:   5%|5         | 5/100 [00:00<00:08, 10.71it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 10 Steps | CPU 58.3 | RAM 52.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 10 Steps | CPU 51.0 | RAM 52.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 10 Steps | CPU 51.0 | RAM 52.9:   2%|2         | 2/100 [00:00<00:07, 12.73it/s]\n",
      "Episode 10 Steps | CPU 60.6 | RAM 53.0:   2%|2         | 2/100 [00:00<00:07, 12.73it/s]\n",
      "Episode 10 Steps | CPU 54.7 | RAM 52.9:   2%|2         | 2/100 [00:00<00:07, 12.73it/s]\n",
      "Episode 10 Steps | CPU 54.7 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 13.15it/s]\n",
      "Episode 10 Steps | CPU 53.2 | RAM 53.0:   4%|4         | 4/100 [00:00<00:07, 13.15it/s]\n",
      "Episode 10 Steps | CPU 58.1 | RAM 53.0:   4%|4         | 4/100 [00:00<00:07, 13.15it/s]\n",
      "Episode 10 Steps | CPU 58.1 | RAM 53.0:   6%|6         | 6/100 [00:00<00:07, 12.02it/s]\n",
      "Episode 10 Steps | CPU 62.2 | RAM 53.0:   6%|6         | 6/100 [00:00<00:07, 12.02it/s]\n",
      "Episode 10 Steps | CPU 63.0 | RAM 53.0:   6%|6         | 6/100 [00:00<00:07, 12.02it/s]\n",
      "Episode 10 Steps | CPU 63.0 | RAM 53.0:   7%|7         | 7/100 [00:00<00:08, 10.44it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 11 Steps | CPU 59.2 | RAM 53.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 11 Steps | CPU 62.3 | RAM 53.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 11 Steps | CPU 62.3 | RAM 53.1:   2%|2         | 2/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 11 Steps | CPU 57.6 | RAM 53.0:   2%|2         | 2/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 11 Steps | CPU 62.3 | RAM 53.1:   2%|2         | 2/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 11 Steps | CPU 62.3 | RAM 53.1:   4%|4         | 4/100 [00:00<00:07, 12.28it/s]\n",
      "Episode 11 Steps | CPU 56.7 | RAM 53.1:   4%|4         | 4/100 [00:00<00:07, 12.28it/s]\n",
      "Episode 11 Steps | CPU 56.7 | RAM 53.1:   4%|4         | 4/100 [00:00<00:09,  9.86it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 12 Steps | CPU 56.9 | RAM 53.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 12 Steps | CPU 50.0 | RAM 53.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 12 Steps | CPU 50.0 | RAM 53.2:   2%|2         | 2/100 [00:00<00:06, 14.01it/s]\n",
      "Episode 12 Steps | CPU 50.0 | RAM 53.2:   2%|2         | 2/100 [00:00<00:06, 14.01it/s]\n",
      "Episode 12 Steps | CPU 52.1 | RAM 53.2:   2%|2         | 2/100 [00:00<00:06, 14.01it/s]\n",
      "Episode 12 Steps | CPU 52.1 | RAM 53.2:   4%|4         | 4/100 [00:00<00:06, 13.98it/s]\n",
      "Episode 12 Steps | CPU 51.7 | RAM 53.2:   4%|4         | 4/100 [00:00<00:06, 13.98it/s]\n",
      "Episode 12 Steps | CPU 54.8 | RAM 53.2:   4%|4         | 4/100 [00:00<00:06, 13.98it/s]\n",
      "Episode 12 Steps | CPU 54.8 | RAM 53.2:   5%|5         | 5/100 [00:00<00:08, 10.89it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 13 Steps | CPU 62.5 | RAM 53.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 13 Steps | CPU 55.7 | RAM 53.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 13 Steps | CPU 55.7 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 13.20it/s]\n",
      "Episode 13 Steps | CPU 53.3 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 13.20it/s]\n",
      "Episode 13 Steps | CPU 53.3 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 13.20it/s]\n",
      "Episode 13 Steps | CPU 53.3 | RAM 53.5:   4%|4         | 4/100 [00:00<00:07, 12.64it/s]\n",
      "Episode 13 Steps | CPU 62.0 | RAM 53.5:   4%|4         | 4/100 [00:00<00:07, 12.64it/s]\n",
      "Episode 13 Steps | CPU 62.9 | RAM 53.5:   4%|4         | 4/100 [00:00<00:07, 12.64it/s]\n",
      "Episode 13 Steps | CPU 62.9 | RAM 53.5:   5%|5         | 5/100 [00:00<00:08, 10.60it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 14 Steps | CPU 51.7 | RAM 53.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 14 Steps | CPU 50.0 | RAM 53.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 14 Steps | CPU 50.0 | RAM 53.6:   2%|2         | 2/100 [00:00<00:07, 13.39it/s]\n",
      "Episode 14 Steps | CPU 51.7 | RAM 53.6:   2%|2         | 2/100 [00:00<00:07, 13.39it/s]\n",
      "Episode 14 Steps | CPU 56.9 | RAM 53.6:   2%|2         | 2/100 [00:00<00:07, 13.39it/s]\n",
      "Episode 14 Steps | CPU 56.9 | RAM 53.6:   4%|4         | 4/100 [00:00<00:08, 11.88it/s]\n",
      "Episode 14 Steps | CPU 66.7 | RAM 53.7:   4%|4         | 4/100 [00:00<00:08, 11.88it/s]\n",
      "Episode 14 Steps | CPU 66.7 | RAM 53.7:   4%|4         | 4/100 [00:00<00:10,  9.48it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 15 Steps | CPU 56.9 | RAM 53.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 15 Steps | CPU 59.0 | RAM 53.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 15 Steps | CPU 59.0 | RAM 53.7:   2%|2         | 2/100 [00:00<00:07, 13.74it/s]\n",
      "Episode 15 Steps | CPU 54.2 | RAM 53.7:   2%|2         | 2/100 [00:00<00:07, 13.74it/s]\n",
      "Episode 15 Steps | CPU 72.6 | RAM 53.0:   2%|2         | 2/100 [00:00<00:07, 13.74it/s]\n",
      "Episode 15 Steps | CPU 72.6 | RAM 53.0:   4%|4         | 4/100 [00:00<00:08, 11.47it/s]\n",
      "Episode 15 Steps | CPU 68.5 | RAM 52.8:   4%|4         | 4/100 [00:00<00:08, 11.47it/s]\n",
      "Episode 15 Steps | CPU 68.5 | RAM 52.8:   4%|4         | 4/100 [00:00<00:10,  9.60it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 16 Steps | CPU 55.7 | RAM 52.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 16 Steps | CPU 56.7 | RAM 52.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 16 Steps | CPU 56.7 | RAM 52.7:   2%|2         | 2/100 [00:00<00:07, 13.06it/s]\n",
      "Episode 16 Steps | CPU 51.7 | RAM 52.7:   2%|2         | 2/100 [00:00<00:07, 13.06it/s]\n",
      "Episode 16 Steps | CPU 55.7 | RAM 52.7:   2%|2         | 2/100 [00:00<00:07, 13.06it/s]\n",
      "Episode 16 Steps | CPU 55.7 | RAM 52.7:   4%|4         | 4/100 [00:00<00:07, 12.98it/s]\n",
      "Episode 16 Steps | CPU 50.0 | RAM 52.7:   4%|4         | 4/100 [00:00<00:07, 12.98it/s]\n",
      "Episode 16 Steps | CPU 50.0 | RAM 52.7:   4%|4         | 4/100 [00:00<00:09, 10.38it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 17 Steps | CPU 50.0 | RAM 52.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 17 Steps | CPU 79.5 | RAM 52.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 17 Steps | CPU 79.5 | RAM 52.8:   2%|2         | 2/100 [00:00<00:08, 11.06it/s]\n",
      "Episode 17 Steps | CPU 68.9 | RAM 52.9:   2%|2         | 2/100 [00:00<00:08, 11.06it/s]\n",
      "Episode 17 Steps | CPU 53.3 | RAM 52.9:   2%|2         | 2/100 [00:00<00:08, 11.06it/s]\n",
      "Episode 17 Steps | CPU 53.3 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 12.79it/s]\n",
      "Episode 17 Steps | CPU 54.2 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 12.79it/s]\n",
      "Episode 17 Steps | CPU 54.2 | RAM 52.9:   4%|4         | 4/100 [00:00<00:09,  9.98it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 18 Steps | CPU 50.8 | RAM 52.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 18 Steps | CPU 50.0 | RAM 52.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 18 Steps | CPU 50.0 | RAM 52.9:   2%|2         | 2/100 [00:00<00:06, 14.27it/s]\n",
      "Episode 18 Steps | CPU 61.2 | RAM 52.9:   2%|2         | 2/100 [00:00<00:06, 14.27it/s]\n",
      "Episode 18 Steps | CPU 65.0 | RAM 52.9:   2%|2         | 2/100 [00:00<00:06, 14.27it/s]\n",
      "Episode 18 Steps | CPU 65.0 | RAM 52.9:   4%|4         | 4/100 [00:00<00:07, 12.75it/s]\n",
      "Episode 18 Steps | CPU 65.8 | RAM 53.0:   4%|4         | 4/100 [00:00<00:07, 12.75it/s]\n",
      "Episode 18 Steps | CPU 65.8 | RAM 53.0:   4%|4         | 4/100 [00:00<00:10,  9.52it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 19 Steps | CPU 63.9 | RAM 53.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 19 Steps | CPU 59.2 | RAM 53.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 19 Steps | CPU 59.2 | RAM 53.0:   2%|2         | 2/100 [00:00<00:07, 13.94it/s]\n",
      "Episode 19 Steps | CPU 50.0 | RAM 53.1:   2%|2         | 2/100 [00:00<00:07, 13.94it/s]\n",
      "Episode 19 Steps | CPU 60.0 | RAM 53.1:   2%|2         | 2/100 [00:00<00:07, 13.94it/s]\n",
      "Episode 19 Steps | CPU 60.0 | RAM 53.1:   4%|4         | 4/100 [00:00<00:07, 12.84it/s]\n",
      "Episode 19 Steps | CPU 67.1 | RAM 53.1:   4%|4         | 4/100 [00:00<00:07, 12.84it/s]\n",
      "Episode 19 Steps | CPU 67.1 | RAM 53.1:   4%|4         | 4/100 [00:00<00:09, 10.21it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 20 Steps | CPU 66.7 | RAM 53.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 20 Steps | CPU 53.3 | RAM 53.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 20 Steps | CPU 53.3 | RAM 53.2:   2%|2         | 2/100 [00:00<00:06, 14.26it/s]\n",
      "Episode 20 Steps | CPU 50.0 | RAM 53.2:   2%|2         | 2/100 [00:00<00:06, 14.26it/s]\n",
      "Episode 20 Steps | CPU 50.0 | RAM 53.2:   2%|2         | 2/100 [00:00<00:06, 14.26it/s]\n",
      "Episode 20 Steps | CPU 50.0 | RAM 53.2:   4%|4         | 4/100 [00:00<00:07, 13.64it/s]\n",
      "Episode 20 Steps | CPU 53.3 | RAM 53.2:   4%|4         | 4/100 [00:00<00:07, 13.64it/s]\n",
      "Episode 20 Steps | CPU 53.3 | RAM 53.2:   4%|4         | 4/100 [00:00<00:08, 10.74it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 21 Steps | CPU 51.4 | RAM 53.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 21 Steps | CPU 60.7 | RAM 53.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 21 Steps | CPU 60.7 | RAM 53.2:   2%|2         | 2/100 [00:00<00:08, 12.14it/s]\n",
      "Episode 21 Steps | CPU 53.8 | RAM 53.3:   2%|2         | 2/100 [00:00<00:08, 12.14it/s]\n",
      "Episode 21 Steps | CPU 60.0 | RAM 53.3:   2%|2         | 2/100 [00:00<00:08, 12.14it/s]\n",
      "Episode 21 Steps | CPU 60.0 | RAM 53.3:   4%|4         | 4/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 21 Steps | CPU 51.7 | RAM 53.3:   4%|4         | 4/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 21 Steps | CPU 50.0 | RAM 53.3:   4%|4         | 4/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 21 Steps | CPU 50.0 | RAM 53.3:   5%|5         | 5/100 [00:00<00:09, 10.17it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 22 Steps | CPU 58.3 | RAM 53.3:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 22 Steps | CPU 60.7 | RAM 53.3:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 22 Steps | CPU 60.7 | RAM 53.3:   2%|2         | 2/100 [00:00<00:08, 11.71it/s]\n",
      "Episode 22 Steps | CPU 57.5 | RAM 53.4:   2%|2         | 2/100 [00:00<00:08, 11.71it/s]\n",
      "Episode 22 Steps | CPU 58.3 | RAM 53.4:   2%|2         | 2/100 [00:00<00:08, 11.71it/s]\n",
      "Episode 22 Steps | CPU 58.3 | RAM 53.4:   4%|4         | 4/100 [00:00<00:07, 12.67it/s]\n",
      "Episode 22 Steps | CPU 55.2 | RAM 53.4:   4%|4         | 4/100 [00:00<00:07, 12.67it/s]\n",
      "Episode 22 Steps | CPU 55.2 | RAM 53.4:   4%|4         | 4/100 [00:00<00:09,  9.87it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 23 Steps | CPU 54.8 | RAM 53.4:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 23 Steps | CPU 60.0 | RAM 53.4:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 23 Steps | CPU 60.0 | RAM 53.4:   2%|2         | 2/100 [00:00<00:07, 12.69it/s]\n",
      "Episode 23 Steps | CPU 66.2 | RAM 53.4:   2%|2         | 2/100 [00:00<00:07, 12.69it/s]\n",
      "Episode 23 Steps | CPU 48.4 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 12.69it/s]\n",
      "Episode 23 Steps | CPU 48.4 | RAM 53.5:   4%|4         | 4/100 [00:00<00:07, 12.98it/s]\n",
      "Episode 23 Steps | CPU 56.9 | RAM 53.5:   4%|4         | 4/100 [00:00<00:07, 12.98it/s]\n",
      "Episode 23 Steps | CPU 56.9 | RAM 53.5:   4%|4         | 4/100 [00:00<00:09, 10.26it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 24 Steps | CPU 50.0 | RAM 53.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 24 Steps | CPU 61.7 | RAM 53.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 24 Steps | CPU 61.7 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 12.57it/s]\n",
      "Episode 24 Steps | CPU 60.0 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 12.57it/s]\n",
      "Episode 24 Steps | CPU 65.8 | RAM 53.5:   2%|2         | 2/100 [00:00<00:07, 12.57it/s]\n",
      "Episode 24 Steps | CPU 65.8 | RAM 53.5:   4%|4         | 4/100 [00:00<00:07, 12.32it/s]\n",
      "Episode 24 Steps | CPU 59.3 | RAM 53.6:   4%|4         | 4/100 [00:00<00:07, 12.32it/s]\n",
      "Episode 24 Steps | CPU 59.3 | RAM 53.6:   4%|4         | 4/100 [00:00<00:09,  9.94it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 25 Steps | CPU 52.5 | RAM 53.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 25 Steps | CPU 67.9 | RAM 53.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 25 Steps | CPU 67.9 | RAM 53.6:   2%|2         | 2/100 [00:00<00:06, 14.99it/s]\n",
      "Episode 25 Steps | CPU 51.7 | RAM 53.6:   2%|2         | 2/100 [00:00<00:06, 14.99it/s]\n",
      "Episode 25 Steps | CPU 51.7 | RAM 53.6:   2%|2         | 2/100 [00:00<00:10,  8.92it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 26 Steps | CPU 52.8 | RAM 53.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 26 Steps | CPU 55.6 | RAM 53.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 26 Steps | CPU 55.6 | RAM 53.6:   2%|2         | 2/100 [00:00<00:06, 14.16it/s]\n",
      "Episode 26 Steps | CPU 52.2 | RAM 53.6:   2%|2         | 2/100 [00:00<00:06, 14.16it/s]\n",
      "Episode 26 Steps | CPU 56.5 | RAM 53.6:   2%|2         | 2/100 [00:00<00:06, 14.16it/s]\n",
      "Episode 26 Steps | CPU 56.5 | RAM 53.6:   3%|3         | 3/100 [00:00<00:09,  9.82it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 27 Steps | CPU 56.5 | RAM 53.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 27 Steps | CPU 57.4 | RAM 53.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 27 Steps | CPU 57.4 | RAM 53.7:   2%|2         | 2/100 [00:00<00:08, 12.01it/s]\n",
      "Episode 27 Steps | CPU 55.6 | RAM 53.7:   2%|2         | 2/100 [00:00<00:08, 12.01it/s]\n",
      "Episode 27 Steps | CPU 52.8 | RAM 53.8:   2%|2         | 2/100 [00:00<00:08, 12.01it/s]\n",
      "Episode 27 Steps | CPU 52.8 | RAM 53.8:   3%|3         | 3/100 [00:00<00:10,  9.02it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 28 Steps | CPU 51.7 | RAM 53.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 28 Steps | CPU 50.0 | RAM 53.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 28 Steps | CPU 50.0 | RAM 53.8:   2%|2         | 2/100 [00:00<00:06, 14.51it/s]\n",
      "Episode 28 Steps | CPU 50.0 | RAM 53.8:   2%|2         | 2/100 [00:00<00:06, 14.51it/s]\n",
      "Episode 28 Steps | CPU 55.1 | RAM 53.8:   2%|2         | 2/100 [00:00<00:06, 14.51it/s]\n",
      "Episode 28 Steps | CPU 55.1 | RAM 53.8:   3%|3         | 3/100 [00:00<00:10,  9.16it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 29 Steps | CPU 52.6 | RAM 53.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 29 Steps | CPU 61.7 | RAM 53.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 29 Steps | CPU 61.7 | RAM 53.8:   2%|2         | 2/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 29 Steps | CPU 56.7 | RAM 53.8:   2%|2         | 2/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 29 Steps | CPU 50.0 | RAM 53.9:   2%|2         | 2/100 [00:00<00:07, 12.46it/s]\n",
      "Episode 29 Steps | CPU 50.0 | RAM 53.9:   3%|3         | 3/100 [00:00<00:10,  9.12it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 30 Steps | CPU 52.1 | RAM 53.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 30 Steps | CPU 54.2 | RAM 53.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 30 Steps | CPU 54.2 | RAM 53.9:   2%|2         | 2/100 [00:00<00:08, 12.03it/s]\n",
      "Episode 30 Steps | CPU 60.3 | RAM 54.0:   2%|2         | 2/100 [00:00<00:08, 12.03it/s]\n",
      "Episode 30 Steps | CPU 62.9 | RAM 54.0:   2%|2         | 2/100 [00:00<00:08, 12.03it/s]\n",
      "Episode 30 Steps | CPU 62.9 | RAM 54.0:   3%|3         | 3/100 [00:00<00:10,  9.32it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 31 Steps | CPU 50.0 | RAM 54.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 31 Steps | CPU 53.1 | RAM 54.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 31 Steps | CPU 53.1 | RAM 54.0:   2%|2         | 2/100 [00:00<00:07, 12.78it/s]\n",
      "Episode 31 Steps | CPU 50.0 | RAM 54.1:   2%|2         | 2/100 [00:00<00:07, 12.78it/s]\n",
      "Episode 31 Steps | CPU 56.2 | RAM 54.1:   2%|2         | 2/100 [00:00<00:07, 12.78it/s]\n",
      "Episode 31 Steps | CPU 56.2 | RAM 54.1:   3%|3         | 3/100 [00:00<00:10,  9.47it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 32 Steps | CPU 60.3 | RAM 54.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 32 Steps | CPU 57.1 | RAM 54.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 32 Steps | CPU 57.1 | RAM 54.1:   2%|2         | 2/100 [00:00<00:08, 12.08it/s]\n",
      "Episode 32 Steps | CPU 53.2 | RAM 54.1:   2%|2         | 2/100 [00:00<00:08, 12.08it/s]\n",
      "Episode 32 Steps | CPU 55.0 | RAM 54.2:   2%|2         | 2/100 [00:00<00:08, 12.08it/s]\n",
      "Episode 32 Steps | CPU 55.0 | RAM 54.2:   3%|3         | 3/100 [00:00<00:10,  9.69it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 33 Steps | CPU 53.3 | RAM 54.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 33 Steps | CPU 54.2 | RAM 54.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 33 Steps | CPU 54.2 | RAM 54.1:   2%|2         | 2/100 [00:00<00:07, 13.92it/s]\n",
      "Episode 33 Steps | CPU 52.5 | RAM 54.2:   2%|2         | 2/100 [00:00<00:07, 13.92it/s]\n",
      "Episode 33 Steps | CPU 49.0 | RAM 54.2:   2%|2         | 2/100 [00:00<00:07, 13.92it/s]\n",
      "Episode 33 Steps | CPU 49.0 | RAM 54.2:   3%|3         | 3/100 [00:00<00:09, 10.62it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 34 Steps | CPU 55.0 | RAM 54.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 34 Steps | CPU 61.7 | RAM 54.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 34 Steps | CPU 61.7 | RAM 54.2:   2%|2         | 2/100 [00:00<00:07, 12.49it/s]\n",
      "Episode 34 Steps | CPU 55.7 | RAM 54.3:   2%|2         | 2/100 [00:00<00:07, 12.49it/s]\n",
      "Episode 34 Steps | CPU 60.3 | RAM 54.3:   2%|2         | 2/100 [00:00<00:07, 12.49it/s]\n",
      "Episode 34 Steps | CPU 60.3 | RAM 54.3:   3%|3         | 3/100 [00:00<00:10,  9.25it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 35 Steps | CPU 49.3 | RAM 54.3:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 35 Steps | CPU 53.3 | RAM 54.3:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 35 Steps | CPU 53.3 | RAM 54.3:   2%|2         | 2/100 [00:00<00:06, 15.03it/s]\n",
      "Episode 35 Steps | CPU 50.0 | RAM 54.3:   2%|2         | 2/100 [00:00<00:06, 15.03it/s]\n",
      "Episode 35 Steps | CPU 49.2 | RAM 54.4:   2%|2         | 2/100 [00:00<00:06, 15.03it/s]\n",
      "Episode 35 Steps | CPU 49.2 | RAM 54.4:   3%|3         | 3/100 [00:00<00:09, 10.26it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 36 Steps | CPU 50.0 | RAM 54.4:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 36 Steps | CPU 52.1 | RAM 54.4:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 36 Steps | CPU 52.1 | RAM 54.4:   2%|2         | 2/100 [00:00<00:06, 14.36it/s]\n",
      "Episode 36 Steps | CPU 53.3 | RAM 54.4:   2%|2         | 2/100 [00:00<00:06, 14.36it/s]\n",
      "Episode 36 Steps | CPU 50.7 | RAM 54.5:   2%|2         | 2/100 [00:00<00:06, 14.36it/s]\n",
      "Episode 36 Steps | CPU 50.7 | RAM 54.5:   3%|3         | 3/100 [00:00<00:10,  9.58it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 37 Steps | CPU 54.2 | RAM 54.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 37 Steps | CPU 57.1 | RAM 54.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 37 Steps | CPU 57.1 | RAM 54.5:   2%|2         | 2/100 [00:00<00:08, 12.00it/s]\n",
      "Episode 37 Steps | CPU 53.4 | RAM 54.4:   2%|2         | 2/100 [00:00<00:08, 12.00it/s]\n",
      "Episode 37 Steps | CPU 54.1 | RAM 54.5:   2%|2         | 2/100 [00:00<00:08, 12.00it/s]\n",
      "Episode 37 Steps | CPU 54.1 | RAM 54.5:   3%|3         | 3/100 [00:00<00:10,  8.95it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 38 Steps | CPU 51.4 | RAM 54.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 38 Steps | CPU 52.1 | RAM 54.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 38 Steps | CPU 52.1 | RAM 54.5:   2%|2         | 2/100 [00:00<00:06, 14.14it/s]\n",
      "Episode 38 Steps | CPU 50.0 | RAM 54.5:   2%|2         | 2/100 [00:00<00:06, 14.14it/s]\n",
      "Episode 38 Steps | CPU 50.0 | RAM 54.5:   2%|2         | 2/100 [00:00<00:10,  9.01it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 39 Steps | CPU 51.7 | RAM 54.5:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 39 Steps | CPU 50.0 | RAM 54.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 39 Steps | CPU 50.0 | RAM 54.6:   2%|2         | 2/100 [00:00<00:07, 12.39it/s]\n",
      "Episode 39 Steps | CPU 50.0 | RAM 54.6:   2%|2         | 2/100 [00:00<00:07, 12.39it/s]\n",
      "Episode 39 Steps | CPU 50.0 | RAM 54.6:   2%|2         | 2/100 [00:00<00:11,  8.25it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 40 Steps | CPU 51.7 | RAM 54.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 40 Steps | CPU 59.0 | RAM 54.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 40 Steps | CPU 59.0 | RAM 54.6:   2%|2         | 2/100 [00:00<00:07, 13.20it/s]\n",
      "Episode 40 Steps | CPU 55.0 | RAM 54.6:   2%|2         | 2/100 [00:00<00:07, 13.20it/s]\n",
      "Episode 40 Steps | CPU 55.0 | RAM 54.6:   2%|2         | 2/100 [00:00<00:11,  8.61it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 41 Steps | CPU 50.0 | RAM 54.6:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 41 Steps | CPU 51.7 | RAM 54.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 41 Steps | CPU 51.7 | RAM 54.7:   2%|2         | 2/100 [00:00<00:07, 12.35it/s]\n",
      "Episode 41 Steps | CPU 50.0 | RAM 54.7:   2%|2         | 2/100 [00:00<00:07, 12.35it/s]\n",
      "Episode 41 Steps | CPU 50.0 | RAM 54.7:   2%|2         | 2/100 [00:00<00:11,  8.60it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 42 Steps | CPU 50.0 | RAM 54.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 42 Steps | CPU 51.7 | RAM 54.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 42 Steps | CPU 51.7 | RAM 54.7:   2%|2         | 2/100 [00:00<00:06, 14.38it/s]\n",
      "Episode 42 Steps | CPU 50.0 | RAM 54.7:   2%|2         | 2/100 [00:00<00:06, 14.38it/s]\n",
      "Episode 42 Steps | CPU 50.0 | RAM 54.7:   2%|2         | 2/100 [00:00<00:10,  9.55it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 43 Steps | CPU 53.3 | RAM 54.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 43 Steps | CPU 50.0 | RAM 54.7:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 43 Steps | CPU 50.0 | RAM 54.7:   2%|2         | 2/100 [00:00<00:07, 13.22it/s]\n",
      "Episode 43 Steps | CPU 56.4 | RAM 54.8:   2%|2         | 2/100 [00:00<00:07, 13.22it/s]\n",
      "Episode 43 Steps | CPU 56.4 | RAM 54.8:   2%|2         | 2/100 [00:00<00:11,  8.63it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 44 Steps | CPU 49.2 | RAM 54.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 44 Steps | CPU 50.0 | RAM 54.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 44 Steps | CPU 50.0 | RAM 54.8:   2%|2         | 2/100 [00:00<00:07, 13.93it/s]\n",
      "Episode 44 Steps | CPU 52.1 | RAM 54.8:   2%|2         | 2/100 [00:00<00:07, 13.93it/s]\n",
      "Episode 44 Steps | CPU 52.1 | RAM 54.8:   2%|2         | 2/100 [00:00<00:10,  8.99it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 45 Steps | CPU 51.4 | RAM 54.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 45 Steps | CPU 58.3 | RAM 54.8:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 45 Steps | CPU 58.3 | RAM 54.8:   2%|2         | 2/100 [00:00<00:07, 13.97it/s]\n",
      "Episode 45 Steps | CPU 54.2 | RAM 54.9:   2%|2         | 2/100 [00:00<00:07, 13.97it/s]\n",
      "Episode 45 Steps | CPU 54.2 | RAM 54.9:   2%|2         | 2/100 [00:00<00:10,  8.92it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 46 Steps | CPU 50.8 | RAM 54.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 46 Steps | CPU 56.7 | RAM 54.9:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 46 Steps | CPU 56.7 | RAM 54.9:   2%|2         | 2/100 [00:00<00:07, 13.19it/s]\n",
      "Episode 46 Steps | CPU 55.0 | RAM 55.0:   2%|2         | 2/100 [00:00<00:07, 13.19it/s]\n",
      "Episode 46 Steps | CPU 50.0 | RAM 55.0:   2%|2         | 2/100 [00:00<00:07, 13.19it/s]\n",
      "Episode 46 Steps | CPU 50.0 | RAM 55.0:   3%|3         | 3/100 [00:00<00:10,  9.36it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 47 Steps | CPU 50.0 | RAM 55.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 47 Steps | CPU 52.1 | RAM 55.0:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 47 Steps | CPU 52.1 | RAM 55.0:   2%|2         | 2/100 [00:00<00:07, 13.18it/s]\n",
      "Episode 47 Steps | CPU 51.7 | RAM 55.1:   2%|2         | 2/100 [00:00<00:07, 13.18it/s]\n",
      "Episode 47 Steps | CPU 51.7 | RAM 55.1:   2%|2         | 2/100 [00:00<00:10,  9.09it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 48 Steps | CPU 51.7 | RAM 55.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 48 Steps | CPU 60.4 | RAM 55.1:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 48 Steps | CPU 60.4 | RAM 55.1:   2%|2         | 2/100 [00:00<00:07, 13.07it/s]\n",
      "Episode 48 Steps | CPU 58.0 | RAM 55.1:   2%|2         | 2/100 [00:00<00:07, 13.07it/s]\n",
      "Episode 48 Steps | CPU 58.0 | RAM 55.1:   2%|2         | 2/100 [00:00<00:11,  8.67it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 49 Steps | CPU 49.2 | RAM 55.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 49 Steps | CPU 54.2 | RAM 55.2:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Episode 49 Steps | CPU 54.2 | RAM 55.2:   2%|2         | 2/100 [00:00<00:06, 15.26it/s]\n",
      "Episode 49 Steps | CPU 50.0 | RAM 55.2:   2%|2         | 2/100 [00:00<00:06, 15.26it/s]\n",
      "Episode 49 Steps | CPU 50.0 | RAM 55.2:   2%|2         | 2/100 [00:00<00:09,  9.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#!python symbolic_dqn\\main.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div()] #Add your own operators here\n",
    "\n",
    "evo = Evolution(\n",
    "  fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "  4,\n",
    "  pop_size=256,\n",
    "  max_gens=10,\n",
    "  max_tree_size=31,\n",
    "  n_jobs=4,\n",
    "  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_score(tree):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(5): #run 5 episodes for baseline\n",
    "      # get initial state\n",
    "      observation = env.reset(seed=i)\n",
    "      observation = observation[0]\n",
    "      observation = np.array([(observation[0]/90), (observation[1]/90), (observation[2]/5), (observation[3]/5), (observation[4]/3.1415927), (observation[5]/5), observation[6], observation[7]])\n",
    "\n",
    "      for _ in range(300): #300 time steps for baseline\n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = torch.argmax(output) # What goes here?\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        observation = np.array([(observation[0]/90), (observation[1]/90), (observation[2]/5), (observation[3]/5), (observation[4]/3.1415927), (observation[5]/5), observation[6], observation[7]])\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "    \n",
    "    return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficient_optimisation():\n",
    "    for best in evo.population:\n",
    "        batch_size = 128\n",
    "        GAMMA = 0.99\n",
    "\n",
    "        constants = best.get_subtrees_consts()\n",
    "        if len(constants)>0:\n",
    "            optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "        for _ in range(500):\n",
    "\n",
    "            if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "                target_tree = copy.deepcopy(best)\n",
    "\n",
    "                transitions = evo.memory.sample(batch_size)\n",
    "                batch = Transition(*zip(*transitions))\n",
    "                \n",
    "                non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                                    batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "                non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                        if s is not None])\n",
    "                state_batch = torch.cat(batch.state)\n",
    "                action_batch = torch.cat(batch.action)\n",
    "                reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "                state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "                next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "                with torch.no_grad():\n",
    "                    next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "                expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "                \n",
    "                criterion = nn.SmoothL1Loss()\n",
    "                loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "            \n",
    "                # Optimize the model\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "                optimizer.step()\n",
    "\n",
    "        best.fitness = evo.fitness_function(best)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 1,\tbest of gen fitness: -437.261,\tbest of gen size: 25\n",
      "gen: 2,\tbest of gen fitness: -432.321,\tbest of gen size: 25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m evo\u001B[38;5;241m.\u001B[39mevolve()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mcoefficient_optimisation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     evo\u001B[38;5;241m.\u001B[39mmax_gens \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[0;32m      7\u001B[0m     evo\u001B[38;5;241m.\u001B[39mevolve_continue()\n",
      "Cell \u001B[1;32mIn[12], line 27\u001B[0m, in \u001B[0;36mcoefficient_optimisation\u001B[1;34m()\u001B[0m\n\u001B[0;32m     24\u001B[0m action_batch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(batch\u001B[38;5;241m.\u001B[39maction)\n\u001B[0;32m     25\u001B[0m reward_batch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(batch\u001B[38;5;241m.\u001B[39mreward)\n\u001B[1;32m---> 27\u001B[0m state_action_values \u001B[38;5;241m=\u001B[39m \u001B[43mbest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_output_pt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_batch\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgather(\u001B[38;5;241m1\u001B[39m, action_batch)\n\u001B[0;32m     28\u001B[0m next_state_values \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(batch_size, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\multitree.py:16\u001B[0m, in \u001B[0;36mMultitree.get_output_pt\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     14\u001B[0m output \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren:\n\u001B[1;32m---> 16\u001B[0m   output\u001B[38;5;241m.\u001B[39mappend(\u001B[43mchild\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_output_pt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output,dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\node_impl.py:46\u001B[0m, in \u001B[0;36mMinus.get_output_pt\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_output_pt\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m---> 46\u001B[0m   c_outs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_child_outputs_pt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m   \u001B[38;5;66;03m# return c_outs[0] - c_outs[1]\u001B[39;00m\n\u001B[0;32m     49\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(c_outs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\node.py:222\u001B[0m, in \u001B[0;36mNode._get_child_outputs_pt\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# for i in range(self.arity):\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_children)):\n\u001B[1;32m--> 222\u001B[0m   c_o \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_children\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_output_pt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m   c_outs\u001B[38;5;241m.\u001B[39mappend(c_o)\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m c_outs\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\node_impl.py:46\u001B[0m, in \u001B[0;36mMinus.get_output_pt\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_output_pt\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m---> 46\u001B[0m   c_outs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_child_outputs_pt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m   \u001B[38;5;66;03m# return c_outs[0] - c_outs[1]\u001B[39;00m\n\u001B[0;32m     49\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(c_outs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\node.py:222\u001B[0m, in \u001B[0;36mNode._get_child_outputs_pt\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# for i in range(self.arity):\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_children)):\n\u001B[1;32m--> 222\u001B[0m   c_o \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_children\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_output_pt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m   c_outs\u001B[38;5;241m.\u001B[39mappend(c_o)\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m c_outs\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\node_impl.py:111\u001B[0m, in \u001B[0;36mDiv.get_output_pt\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;66;03m# sign_b = torch.sign(c_outs[1])\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;66;03m# sign_b = torch.where(sign_b == 0, 1, sign_b) \u001B[39;00m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# protected_div = sign_b * c_outs[0] / (1e-9 + torch.abs(c_outs[1]))\u001B[39;00m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;66;03m# return protected_div\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(c_outs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    109\u001B[0m   \u001B[38;5;66;03m# sign_b = torch.sign(c_outs[1])\u001B[39;00m\n\u001B[0;32m    110\u001B[0m   \u001B[38;5;66;03m# sign_b = torch.where(sign_b == 0, 1, sign_b) \u001B[39;00m\n\u001B[1;32m--> 111\u001B[0m   sign_b \u001B[38;5;241m=\u001B[39m \u001B[43msign\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc_outs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m   protected_div \u001B[38;5;241m=\u001B[39m sign_b \u001B[38;5;241m*\u001B[39m c_outs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1e-9\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mabs\u001B[39m(c_outs[\u001B[38;5;241m1\u001B[39m]))\n\u001B[0;32m    113\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m protected_div\n",
      "File \u001B[1;32m~\\Documents\\Important\\Evolutionary Algorithms\\pycharm\\genepro\\node_impl.py:6\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m sign \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopysign\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mPlus\u001B[39;00m(Node, nn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      9\u001B[0m   \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
      "\u001B[1;31mValueError\u001B[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "evo.evolve()\n",
    "\n",
    "#for i in range(1):\n",
    "#    coefficient_optimisation()\n",
    "#    evo.max_gens += 5\n",
    "#    evo.evolve_continue()\n",
    "\n",
    "end_time = time.time()\n",
    "comp_time = end_time-start_time\n",
    "print(f\"Computation time: {comp_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_counter =0\n",
    "gen = range(len(evo.best_of_gens)) #generation\n",
    "avg_rewards = [] #average reward\n",
    "for i in evo.best_of_gens:\n",
    "    #print(\"for gen\",gen_counter)\n",
    "    avg_reward = get_test_score(i)/5\n",
    "    avg_rewards.append(avg_reward)\n",
    "    #print(\"average reward was:\",avg_reward)\n",
    "    #print(\"fitness was:\",i.fitness)\n",
    "    #gen_counter += 1\n",
    "#print(\"best of gens\",evo.best_of_gens)\n",
    "\n",
    "#plot generation vs fitness\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gen,avg_rewards)\n",
    "ax.set_xlabel('Generation')\n",
    "ax.set_ylabel('Average Reward')\n",
    "ax.set_title('Average reward gained for five episodes by generation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "best = evo.best_of_gens[-1]\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#test imagemagick\n",
    "#!magick --version\n",
    "\n",
    "#!conda install -c conda-forge imagemagick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "print(\"before\", get_test_score(best))\n",
    "if len(constants)>0:\n",
    "  optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "  if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "    target_tree = copy.deepcopy(best)\n",
    "\n",
    "    transitions = evo.memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                        batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                               if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "      next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "   \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "    optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(\"after\", get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename='evolved_lander_RL.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fd35777e",
   "language": "python",
   "display_name": "PyCharm (pycharm)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}